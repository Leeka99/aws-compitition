import streamlit as st
import boto3
import json
import random
import re
from botocore.config import Config

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë©”ëª¨ ê¸°ë°˜ AI ì§ˆë¬¸ ìƒì„±ê¸°", page_icon="ğŸ“")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'memos' not in st.session_state:
    st.session_state.memos = {}
if 'categories' not in st.session_state:
    st.session_state.categories = []
if 'current_category' not in st.session_state:
    st.session_state.current_category = None
if 'generated_question' not in st.session_state:
    st.session_state.generated_question = None
if 'user_answer' not in st.session_state:
    st.session_state.user_answer = ""

# AWS Bedrock í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” í•¨ìˆ˜
def get_bedrock_client():
    session = boto3.Session()
    client = session.client(
        service_name='bedrock-runtime',
        region_name='us-east-1',
        config=Config(
            retries={'max_attempts': 10, 'mode': 'adaptive'}
        )
    )
    return client

# ì§ˆë¬¸ ìƒì„± í•¨ìˆ˜
def generate_question(prompt):
    try:
        bedrock_runtime = get_bedrock_client()
        instruction = f"Human: ë‹¤ìŒ ë©”ëª¨ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê´€ë ¨ëœ ì—¬ëŸ¬ ê°œì˜ ì§ˆë¬¸ì„ ë§Œë“¤ì–´ ì£¼ì„¸ìš”:\n\n{prompt}\n\nAssistant: ë„¤, ì´í•´í–ˆìŠµë‹ˆë‹¤. ë©”ëª¨ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê´€ë ¨ ì§ˆë¬¸ë“¤ì„ ìƒì„±í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤:\n\n1."
        
        body = json.dumps({
            "prompt": instruction,
            "max_tokens_to_sample": 500,
            "temperature": 0.7,
            "top_p": 0.9,
            "stop_sequences": ["\n\nHuman:"]
        })
        
        response = bedrock_runtime.invoke_model(
            modelId="anthropic.claude-v2",
            body=body
        )
        
        response_body = json.loads(response.get('body').read())
        generated_text = response_body.get('completion', '')
        
        questions = re.findall(r'\d+\.\s*(.*)', generated_text)
        if not questions:
            st.error("ìƒì„±ëœ í…ìŠ¤íŠ¸ì—ì„œ ì§ˆë¬¸ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        return random.choice(questions).strip()
        
    except Exception as e:
        st.error(f"ì§ˆë¬¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None

# í”¼ë“œë°± ì œê³µ í•¨ìˆ˜
def provide_feedback(question, user_answer):
    try:
        bedrock_runtime = get_bedrock_client()
        instruction = f"Human: ë‹¤ìŒ ì§ˆë¬¸ê³¼ ì‚¬ìš©ìì˜ ë‹µë³€ì— ëŒ€í•´ ìì„¸í•˜ê³  ì¹œì ˆí•œ í”¼ë“œë°±ì„ ì œê³µí•´ ì£¼ì„¸ìš”.\n\nì§ˆë¬¸: {question}\n\nì‚¬ìš©ìì˜ ë‹µë³€: {user_answer}\n\nAssistant: ë„¤, ì´í•´í–ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ê³¼ ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ í”¼ë“œë°±ì„ ì œê³µí•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n\n"
        
        body = json.dumps({
            "prompt": instruction,
            "max_tokens_to_sample": 300,
            "temperature": 0.7,
            "top_p": 0.9,
            "stop_sequences": ["\n\nHuman:"]
        })
        
        response = bedrock_runtime.invoke_model(
            modelId="anthropic.claude-v2",
            body=body
        )
        
        response_body = json.loads(response.get('body').read())
        return response_body.get('completion', '').strip()
        
    except Exception as e:
        st.error(f"í”¼ë“œë°± ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None

def show_ai_question_generator():
    st.title("AI ì§ˆë¬¸ ìƒì„±ê¸° (ë©”ëª¨ê¸°ë°˜) ğŸ¤–")

    categories = list(st.session_state.memos.keys())
    if categories:
        selected_category = st.selectbox("ì¹´í…Œê³ ë¦¬ ì„ íƒ", categories)
        
        if st.button("ì§ˆë¬¸ ìƒì„±í•˜ê¸°"):
            if selected_category:
                st.session_state.current_category = selected_category
                memo_items = st.session_state.memos[selected_category]
                if memo_items:
                    title, memo = random.choice(list(memo_items.items()))
                    with st.spinner("ì§ˆë¬¸ ìƒì„± ì¤‘..."):
                        generated_question = generate_question(memo)
                        if generated_question:
                            st.session_state.generated_question = generated_question
                            st.session_state.user_answer = ""
                            st.write(f"**ìƒì„±ëœ ì§ˆë¬¸:** {generated_question}")
                else:
                    st.warning("ì´ ì¹´í…Œê³ ë¦¬ì—ëŠ” ë©”ëª¨ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.warning("ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")

        if st.session_state.generated_question:
            st.session_state.user_answer = st.text_input("ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”", st.session_state.user_answer)
            
            if st.button("í”¼ë“œë°± ë°›ê¸°"):
                if st.session_state.user_answer.strip() == "":
                    st.warning("ë‹µë³€ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
                else:
                    with st.spinner("í”¼ë“œë°± ìƒì„± ì¤‘..."):
                        feedback = provide_feedback(st.session_state.generated_question, st.session_state.user_answer)
                        if feedback:
                            st.write(f"**í”¼ë“œë°±:** {feedback}")
    else:
        st.warning("ì €ì¥ëœ ë©”ëª¨ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë©”ëª¨ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.")

def main():
    show_ai_question_generator()

if __name__ == "__main__":
    main()